# Notebooks - Processamento de Laudos

## üìã Notebooks Dispon√≠veis

### 1. `01_processar_laudos.py`
Notebook de teste e desenvolvimento para processar laudos individuais ou pequenos lotes.

**Uso:**
- Testar o sistema com laudos de exemplo
- Debug de erros de estrutura√ß√£o
- Valida√ß√£o de qualidade
- Ajuste de prompts

### 2. `02_processar_csv_mamografia.py` ‚≠ê
Notebook de produ√ß√£o para processar CSVs completos de mamografias.

**Input:** CSV com colunas:
- `CD_ATENDIMENTO` (obrigat√≥rio)
- `DS_LAUDO_MEDICO` (obrigat√≥rio)
- `NM_PROCEDIMENTO` (recomendado)
- `CD_OCORRENCIA` (opcional)
- `CD_ORDEM` (opcional)
- `CD_PROCEDIMENTO` (opcional)
- `DT_PROCEDIMENTO_REALIZADO` (opcional)

**Output:** Delta Table com:
- Laudo original
- Laudo estruturado (JSON)
- Metadados extra√≠dos (BI-RADS, ACR, achados)
- M√©tricas de confian√ßa
- Anota√ß√µes da LLM
- Erros de valida√ß√£o (se houver)

## üöÄ Como Usar `02_processar_csv_mamografia.py`

### Pr√©-requisitos

1. **Ollama + Phi-4 rodando:**
```bash
# No Databricks cluster
%sh
curl -fsSL https://ollama.com/install.sh | sh
nohup ollama serve > /tmp/ollama.log 2>&1 &
ollama pull phi4:14b
```

2. **Projeto clonado no Workspace:**
```bash
%sh
cd /Workspace/Users/seu_usuario/
git clone https://github.com/eduardocaminha/radiologia-extracao-mamografia.git
```

### Passo a Passo

1. **Abrir notebook no Databricks**
   - Workspace ‚Üí Import ‚Üí `02_processar_csv_mamografia.py`

2. **Configurar par√¢metros** (Se√ß√£o 2):
```python
CSV_PATH = "/seu/caminho/para/laudos.csv"
OUTPUT_TABLE = "seu_catalog.seu_schema.mamografia_estruturada"
BATCH_SIZE = 100
```

3. **Atualizar paths** (Se√ß√£o 1 e 3):
```python
sys.path.append("/Workspace/Users/SEU_USUARIO/radiologia-extracao-mamografia")

extractor = LaudoExtractor(
    template_path="/Workspace/Users/SEU_USUARIO/radiologia-extracao-mamografia/config/template.json",
    prompt_path="/Workspace/Users/SEU_USUARIO/radiologia-extracao-mamografia/config/prompt_extracao_mamografia.md"
)
```

4. **Executar todas as c√©lulas**
   - Run All (Shift + Ctrl + Enter)

### Output

O notebook gera:

#### Tabela Delta com colunas:
- **Originais:** `cd_atendimento`, `texto_original`, `nm_procedimento`, etc
- **Estruturadas:** `laudo_estruturado` (JSON completo)
- **Extra√≠das:** `birads`, `acr`, `num_achados`
- **Qualidade:** `confianca_media`, `confianca_minima`, `tem_erros_validacao`
- **Metadados:** `processamento_sucesso`, `processamento_timestamp`, `modelo_llm`

#### An√°lises autom√°ticas:
1. Estat√≠sticas gerais (taxa de sucesso, confian√ßa)
2. Distribui√ß√£o BI-RADS
3. Distribui√ß√£o ACR (densidade mam√°ria)
4. Distribui√ß√£o de achados
5. Casos de baixa confian√ßa (<0.7)
6. Erros de processamento

## üìä Queries √öteis

### Consultar laudos processados
```sql
SELECT 
    cd_atendimento,
    birads,
    acr,
    num_achados,
    confianca_media,
    laudo_estruturado
FROM seu_catalog.seu_schema.mamografia_estruturada
WHERE dt_processamento = CURRENT_DATE
    AND processamento_sucesso = true
    AND birads IN ('4', '5')
```

### Extrair achados espec√≠ficos
```sql
SELECT 
    cd_atendimento,
    birads,
    get_json_object(laudo_estruturado, '$.descricao_achados') as achados
FROM seu_catalog.seu_schema.mamografia_estruturada
WHERE num_achados > 0
```

### Casos para revis√£o m√©dica
```sql
SELECT *
FROM seu_catalog.seu_schema.mamografia_estruturada
WHERE birads IN ('4', '5')
    OR confianca_media < 0.7
    OR tem_erros_validacao = true
ORDER BY birads DESC, confianca_media ASC
```

## üîß Troubleshooting

### Erro: "Ollama n√£o dispon√≠vel"
```bash
# Verificar se est√° rodando
%sh
curl http://localhost:11434/api/tags

# Se n√£o estiver, iniciar
%sh
nohup ollama serve > /tmp/ollama.log 2>&1 &
sleep 5
ollama list
```

### Erro: "Modelo phi4:14b n√£o encontrado"
```bash
%sh
ollama pull phi4:14b
ollama list
```

### Erro: Mem√≥ria insuficiente
Ajustar `BATCH_SIZE` para valor menor:
```python
BATCH_SIZE = 50  # ou 25 para clusters menores
```

### Performance lenta
- Usar cluster com GPU (g5.xlarge ou maior)
- Aumentar `BATCH_SIZE` se tiver mem√≥ria dispon√≠vel
- Considerar processar subset primeiro para validar

## üìà Performance Esperada

| Cluster | GPU | Laudos/min | Custo estimado |
|---------|-----|-----------|----------------|
| CPU only | - | ~5-10 | Baixo |
| g5.xlarge | A10G | ~30-40 | M√©dio |
| g5.2xlarge | A10G | ~50-60 | Alto |

**Exemplo:** 10.000 laudos
- g5.xlarge: ~4-5 horas
- Custo: ~$10-15 (DBU + compute)

## üìù Valida√ß√£o de Qualidade

Ap√≥s processar, sempre:

1. **Verificar taxa de sucesso** (alvo: >95%)
2. **Revisar confian√ßa m√©dia** (alvo: >0.85)
3. **Analisar casos de baixa confian√ßa**
4. **Validar amostra com m√©dicos** (20-50 laudos)
5. **Revisar todos BI-RADS 4 e 5**

## üîÑ Reprocessamento

Para reprocessar laudos com erros:
```python
# Filtrar apenas erros do dia
df_erros = spark.sql("""
    SELECT cd_atendimento, texto_original
    FROM seu_catalog.seu_schema.mamografia_estruturada
    WHERE dt_processamento = CURRENT_DATE
        AND processamento_sucesso = false
""")

# Reprocessar (adaptar c√≥digo da se√ß√£o 6)
```

## üìß Suporte

Para d√∫vidas ou issues:
- GitHub: https://github.com/eduardocaminha/radiologia-extracao-mamografia/issues

