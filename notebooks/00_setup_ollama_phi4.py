# Databricks notebook source
# MAGIC %md
# MAGIC # Setup Ollama + Phi-4 (Databricks - Sem Sudo)
# MAGIC 
# MAGIC **Executar 1x por cluster** antes de processar laudos
# MAGIC 
# MAGIC Este notebook:
# MAGIC 1. Instala Ollama em diret√≥rio local (sem sudo)
# MAGIC 2. Inicia o servi√ßo
# MAGIC 3. Baixa o modelo Phi-4 14B
# MAGIC 4. Valida instala√ß√£o
# MAGIC 
# MAGIC **Tempo estimado:** ~15 minutos (download 8GB)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Baixar Ollama (Instala√ß√£o Local)

# COMMAND ----------

# MAGIC %sh
# MAGIC # Criar diret√≥rio local
# MAGIC mkdir -p /tmp/ollama_install
# MAGIC cd /tmp/ollama_install
# MAGIC 
# MAGIC # Baixar bin√°rio
# MAGIC curl -L https://ollama.com/download/ollama-linux-amd64 -o ollama
# MAGIC chmod +x ollama
# MAGIC 
# MAGIC # Criar link em path local
# MAGIC mkdir -p ~/.local/bin
# MAGIC cp ollama ~/.local/bin/ollama
# MAGIC 
# MAGIC echo "‚úÖ Ollama baixado para ~/.local/bin/ollama"

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Configurar PATH

# COMMAND ----------

import os
os.environ['PATH'] = f"{os.path.expanduser('~/.local/bin')}:{os.environ['PATH']}"

# Testar
import subprocess
result = subprocess.run(['which', 'ollama'], capture_output=True, text=True)
if result.returncode == 0:
    print(f"‚úÖ Ollama encontrado em: {result.stdout.strip()}")
else:
    print("‚ùå Ollama n√£o encontrado no PATH")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Iniciar Servi√ßo Ollama

# COMMAND ----------

import subprocess
import time
import os

# Adicionar PATH
os.environ['PATH'] = f"{os.path.expanduser('~/.local/bin')}:{os.environ['PATH']}"

# Matar processos anteriores
subprocess.run(['pkill', '-f', 'ollama'], stderr=subprocess.DEVNULL)
time.sleep(2)

# Iniciar novo servi√ßo
print("Iniciando Ollama...")
process = subprocess.Popen(
    [os.path.expanduser('~/.local/bin/ollama'), 'serve'],
    stdout=open('/tmp/ollama.log', 'w'),
    stderr=subprocess.STDOUT,
    env=os.environ
)

# Aguardar inicializa√ß√£o
time.sleep(10)

print(f"‚úÖ Ollama iniciado (PID: {process.pid})")
print("Logs em: /tmp/ollama.log")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Testar Conex√£o

# COMMAND ----------

import requests
import time

# Aguardar servi√ßo estar pronto
for i in range(10):
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code == 200:
            print("‚úÖ Ollama est√° respondendo!")
            break
    except:
        print(f"Tentativa {i+1}/10 - Aguardando Ollama iniciar...")
        time.sleep(3)
else:
    print("‚ùå Ollama n√£o respondeu ap√≥s 30 segundos")
    print("\nüìã √öltimas linhas do log:")

# COMMAND ----------

# Ver √∫ltimas linhas do log
print("üìã LOG DO OLLAMA:")
print("=" * 80)

# COMMAND ----------

# MAGIC %sh
# MAGIC tail -30 /tmp/ollama.log

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Baixar Modelo Phi-4 14B
# MAGIC 
# MAGIC **Download: ~8GB, pode demorar 10-15 minutos**

# COMMAND ----------

import subprocess
import os

# Garantir PATH
os.environ['PATH'] = f"{os.path.expanduser('~/.local/bin')}:{os.environ['PATH']}"

print("Baixando Phi-4 14B (isso vai demorar ~10-15 min)...")
print("=" * 80)

result = subprocess.run(
    [os.path.expanduser('~/.local/bin/ollama'), 'pull', 'phi4:14b'],
    capture_output=True,
    text=True,
    env=os.environ
)

print(result.stdout)
if result.returncode == 0:
    print("=" * 80)
    print("‚úÖ Phi-4 14B baixado com sucesso!")
else:
    print("=" * 80)
    print("‚ùå Erro ao baixar Phi-4:")
    print(result.stderr)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. Listar Modelos Instalados

# COMMAND ----------

import subprocess
import os

os.environ['PATH'] = f"{os.path.expanduser('~/.local/bin')}:{os.environ['PATH']}"

result = subprocess.run(
    [os.path.expanduser('~/.local/bin/ollama'), 'list'],
    capture_output=True,
    text=True,
    env=os.environ
)

print("üì¶ MODELOS INSTALADOS:")
print("=" * 80)
print(result.stdout)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. Testar Modelo Phi-4

# COMMAND ----------

import requests
import json

# Testar gera√ß√£o
payload = {
    "model": "phi4:14b",
    "prompt": "Responda apenas: OK",
    "stream": False,
    "options": {
        "temperature": 0.1,
        "num_predict": 10
    }
}

try:
    response = requests.post(
        "http://localhost:11434/api/generate",
        json=payload,
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        print("‚úÖ Phi-4 funcionando!")
        print(f"Resposta: {result['response']}")
        print(f"Tokens gerados: {result.get('eval_count', 'N/A')}")
    else:
        print(f"‚ùå Erro: {response.status_code}")
        print(response.text)
        
except Exception as e:
    print(f"‚ùå Erro ao testar modelo: {e}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 8. Teste com JSON Estruturado

# COMMAND ----------

import requests
import json

# Testar gera√ß√£o de JSON
prompt = """Extraia o BI-RADS do laudo abaixo e retorne em JSON:

LAUDO: Mamografia bilateral normal. BI-RADS 1. Controle em 12 meses.

Retorne apenas:
{"birads": "1", "descricao": "normal"}
"""

payload = {
    "model": "phi4:14b",
    "prompt": prompt,
    "stream": False,
    "format": "json",
    "options": {
        "temperature": 0.1,
        "num_predict": 100
    }
}

try:
    response = requests.post(
        "http://localhost:11434/api/generate",
        json=payload,
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        output = json.loads(result['response'])
        print("‚úÖ Gera√ß√£o de JSON funcionando!")
        print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        print(f"‚ùå Erro: {response.status_code}")
        
except Exception as e:
    print(f"‚ùå Erro: {e}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 9. Verifica√ß√£o Final

# COMMAND ----------

import requests
import os

print("=" * 80)
print("VERIFICA√á√ÉO FINAL - OLLAMA + PHI-4")
print("=" * 80)

# 1. Ollama instalado?
ollama_path = os.path.expanduser('~/.local/bin/ollama')
if os.path.exists(ollama_path):
    print(f"‚úÖ Ollama: Instalado em {ollama_path}")
else:
    print("‚ùå Ollama: Bin√°rio n√£o encontrado")

# 2. Servi√ßo rodando?
try:
    response = requests.get("http://localhost:11434/api/tags", timeout=5)
    if response.status_code == 200:
        print("‚úÖ Ollama: Servi√ßo rodando")
        modelos = response.json()["models"]
        print(f"   Modelos instalados: {len(modelos)}")
        for m in modelos:
            size_gb = m.get('size', 0) / 1e9
            print(f"   - {m['name']} ({size_gb:.1f} GB)")
    else:
        print("‚ùå Ollama: Servi√ßo n√£o est√° respondendo")
except Exception as e:
    print(f"‚ùå Ollama: N√£o acess√≠vel - {e}")

# 3. Phi-4 dispon√≠vel?
try:
    response = requests.get("http://localhost:11434/api/tags", timeout=5)
    modelos = [m["name"] for m in response.json()["models"]]
    if any("phi4" in m for m in modelos):
        print("‚úÖ Phi-4: Instalado e dispon√≠vel")
    else:
        print("‚ùå Phi-4: N√£o encontrado")
except:
    print("‚ùå Phi-4: N√£o foi poss√≠vel verificar")

# 4. Gera√ß√£o funciona?
try:
    test_response = requests.post(
        "http://localhost:11434/api/generate",
        json={"model": "phi4:14b", "prompt": "teste", "stream": False},
        timeout=30
    )
    if test_response.status_code == 200:
        print("‚úÖ Gera√ß√£o: Funcionando")
    else:
        print("‚ùå Gera√ß√£o: Erro")
except Exception as e:
    print(f"‚ùå Gera√ß√£o: Falhou - {e}")

print("=" * 80)
print("\nüìå PR√ìXIMO PASSO:")
print("   Execute: notebooks/02_processar_csv_mamografia.py (produ√ß√£o)")
print("=" * 80)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Troubleshooting

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ver logs do Ollama

# COMMAND ----------

# MAGIC %sh
# MAGIC echo "üìã √öLTIMAS 50 LINHAS DO LOG:"
# MAGIC echo "=========================================="
# MAGIC tail -50 /tmp/ollama.log

# COMMAND ----------

# MAGIC %md
# MAGIC ### Reiniciar Ollama (se necess√°rio)

# COMMAND ----------

import subprocess
import time
import os

# Configurar PATH
os.environ['PATH'] = f"{os.path.expanduser('~/.local/bin')}:{os.environ['PATH']}"

# Matar processos
subprocess.run(['pkill', '-f', 'ollama'], stderr=subprocess.DEVNULL)
time.sleep(2)

# Reiniciar
process = subprocess.Popen(
    [os.path.expanduser('~/.local/bin/ollama'), 'serve'],
    stdout=open('/tmp/ollama.log', 'w'),
    stderr=subprocess.STDOUT,
    env=os.environ
)

time.sleep(10)
print(f"‚úÖ Ollama reiniciado (PID: {process.pid})")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Redownload do modelo (se corrompido)

# COMMAND ----------

# import subprocess
# import os
# 
# os.environ['PATH'] = f"{os.path.expanduser('~/.local/bin')}:{os.environ['PATH']}"
# 
# # Remover modelo
# subprocess.run([os.path.expanduser('~/.local/bin/ollama'), 'rm', 'phi4:14b'], env=os.environ)
# 
# # Redownload
# subprocess.run([os.path.expanduser('~/.local/bin/ollama'), 'pull', 'phi4:14b'], env=os.environ)

# COMMAND ----------

# MAGIC %md
# MAGIC ## ‚ö†Ô∏è Importante: Persist√™ncia no Cluster
# MAGIC 
# MAGIC **Ollama √© instalado em `/tmp/` e `~/.local/`** - esses diret√≥rios podem ser limpos quando o cluster reinicia.
# MAGIC 
# MAGIC **Op√ß√µes:**
# MAGIC 1. **Reexecutar este notebook** ap√≥s restart do cluster (~2 min se Phi-4 j√° estiver em cache)
# MAGIC 2. **Usar Init Script** (configurar no cluster para instalar automaticamente)
# MAGIC 3. **Usar cluster de longa dura√ß√£o** (n√£o desligar entre jobs)
# MAGIC 
# MAGIC Para criar Init Script, veja documenta√ß√£o em: notebooks/README.md
