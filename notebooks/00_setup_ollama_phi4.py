# Databricks notebook source
# MAGIC %md
# MAGIC # Setup Ollama + Phi-4
# MAGIC 
# MAGIC **Executar 1x por cluster** antes de processar laudos
# MAGIC 
# MAGIC Este notebook:
# MAGIC 1. Instala Ollama
# MAGIC 2. Inicia o servi√ßo
# MAGIC 3. Baixa o modelo Phi-4 14B
# MAGIC 4. Valida instala√ß√£o
# MAGIC 
# MAGIC **Tempo estimado:** ~15 minutos (download 8GB)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Instalar Ollama

# COMMAND ----------

# MAGIC %sh
# MAGIC curl -fsSL https://ollama.com/install.sh | sh

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Iniciar Servi√ßo Ollama

# COMMAND ----------

# MAGIC %sh
# MAGIC # Matar processos anteriores se existirem
# MAGIC pkill ollama || true
# MAGIC 
# MAGIC # Iniciar novo servi√ßo em background
# MAGIC nohup ollama serve > /tmp/ollama.log 2>&1 &
# MAGIC 
# MAGIC # Aguardar inicializa√ß√£o
# MAGIC sleep 10
# MAGIC 
# MAGIC # Verificar status
# MAGIC echo "Status do servi√ßo:"
# MAGIC ps aux | grep ollama | grep -v grep || echo "Ollama n√£o est√° rodando"

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Testar Conex√£o

# COMMAND ----------

import requests
import time

# Aguardar servi√ßo estar pronto
for i in range(10):
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code == 200:
            print("‚úÖ Ollama est√° rodando!")
            break
    except:
        print(f"Tentativa {i+1}/10 - Aguardando Ollama iniciar...")
        time.sleep(3)
else:
    print("‚ùå Ollama n√£o respondeu ap√≥s 30 segundos")
    print("Verifique logs: %sh cat /tmp/ollama.log")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Baixar Modelo Phi-4 14B
# MAGIC 
# MAGIC **Download: ~8GB, pode demorar 10-15 minutos**

# COMMAND ----------

# MAGIC %sh
# MAGIC ollama pull phi4:14b

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Listar Modelos Instalados

# COMMAND ----------

# MAGIC %sh
# MAGIC ollama list

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. Testar Modelo Phi-4

# COMMAND ----------

import requests
import json

# Testar gera√ß√£o
payload = {
    "model": "phi4:14b",
    "prompt": "Responda apenas: OK",
    "stream": False,
    "options": {
        "temperature": 0.1,
        "num_predict": 10
    }
}

try:
    response = requests.post(
        "http://localhost:11434/api/generate",
        json=payload,
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        print("‚úÖ Phi-4 funcionando!")
        print(f"Resposta: {result['response']}")
    else:
        print(f"‚ùå Erro: {response.status_code}")
        print(response.text)
        
except Exception as e:
    print(f"‚ùå Erro ao testar modelo: {e}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. Teste com JSON Estruturado

# COMMAND ----------

import requests
import json

# Testar gera√ß√£o de JSON
prompt = """Extraia o BI-RADS do laudo abaixo e retorne em JSON:

LAUDO: Mamografia bilateral normal. BI-RADS 1. Controle em 12 meses.

Retorne apenas:
{"birads": "1", "descricao": "normal"}
"""

payload = {
    "model": "phi4:14b",
    "prompt": prompt,
    "stream": False,
    "format": "json",
    "options": {
        "temperature": 0.1,
        "num_predict": 100
    }
}

try:
    response = requests.post(
        "http://localhost:11434/api/generate",
        json=payload,
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        output = json.loads(result['response'])
        print("‚úÖ Gera√ß√£o de JSON funcionando!")
        print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        print(f"‚ùå Erro: {response.status_code}")
        
except Exception as e:
    print(f"‚ùå Erro: {e}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 8. Verifica√ß√£o Final

# COMMAND ----------

import requests

print("=" * 80)
print("VERIFICA√á√ÉO FINAL - OLLAMA + PHI-4")
print("=" * 80)

# 1. Servi√ßo rodando?
try:
    response = requests.get("http://localhost:11434/api/tags", timeout=5)
    if response.status_code == 200:
        print("‚úÖ Ollama: Rodando")
        modelos = response.json()["models"]
        print(f"   Modelos instalados: {len(modelos)}")
        for m in modelos:
            print(f"   - {m['name']} ({m['size'] / 1e9:.1f} GB)")
    else:
        print("‚ùå Ollama: Erro de conex√£o")
except Exception as e:
    print(f"‚ùå Ollama: N√£o acess√≠vel - {e}")

# 2. Phi-4 dispon√≠vel?
try:
    response = requests.get("http://localhost:11434/api/tags", timeout=5)
    modelos = [m["name"] for m in response.json()["models"]]
    if any("phi4" in m for m in modelos):
        print("‚úÖ Phi-4: Instalado")
    else:
        print("‚ùå Phi-4: N√£o encontrado")
        print("   Execute: %sh ollama pull phi4:14b")
except:
    print("‚ùå Phi-4: N√£o foi poss√≠vel verificar")

# 3. Gera√ß√£o funciona?
try:
    test_response = requests.post(
        "http://localhost:11434/api/generate",
        json={"model": "phi4:14b", "prompt": "teste", "stream": False},
        timeout=30
    )
    if test_response.status_code == 200:
        print("‚úÖ Gera√ß√£o: Funcionando")
    else:
        print("‚ùå Gera√ß√£o: Erro")
except Exception as e:
    print(f"‚ùå Gera√ß√£o: Falhou - {e}")

print("=" * 80)
print("\nüìå PR√ìXIMO PASSO:")
print("   Execute: notebooks/01_processar_laudos.py (testes)")
print("   Ou: notebooks/02_processar_csv_mamografia.py (produ√ß√£o)")
print("=" * 80)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Troubleshooting

# COMMAND ----------

# Ver logs do Ollama
print("üìã √öLTIMAS 50 LINHAS DO LOG:")
print("=" * 80)

# COMMAND ----------

# MAGIC %sh
# MAGIC tail -50 /tmp/ollama.log

# COMMAND ----------

# Reiniciar Ollama se necess√°rio
# COMANDO: Descomente e execute se precisar reiniciar

# %sh
# pkill ollama
# nohup ollama serve > /tmp/ollama.log 2>&1 &
# sleep 10

# COMMAND ----------

# Redownload do modelo se necess√°rio
# COMANDO: Descomente se o modelo estiver corrompido

# %sh
# ollama rm phi4:14b
# ollama pull phi4:14b

